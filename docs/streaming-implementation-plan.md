# AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè£…è¨ˆç”»

## ç›®æ¬¡

1. [æ¦‚è¦](#æ¦‚è¦)
2. [å®Ÿç¾ã—ãŸã„ã“ã¨](#å®Ÿç¾ã—ãŸã„ã“ã¨)
3. [æŠ€è¡“çš„èƒŒæ™¯](#æŠ€è¡“çš„èƒŒæ™¯)
4. [ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ](#ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ)
5. [å®Ÿè£…ã‚¹ãƒ†ãƒƒãƒ—](#å®Ÿè£…ã‚¹ãƒ†ãƒƒãƒ—)
6. [ãƒ†ã‚¹ãƒˆè¨ˆç”»](#ãƒ†ã‚¹ãƒˆè¨ˆç”»)
7. [ãƒªã‚¹ã‚¯ã¨å¯¾ç­–](#ãƒªã‚¹ã‚¯ã¨å¯¾ç­–)
8. [å®Ÿè£…ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ](#å®Ÿè£…ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ)
9. [ã¾ã¨ã‚](#ã¾ã¨ã‚)

---

## æ¦‚è¦

### å®Ÿç¾ã—ãŸã„æ©Ÿèƒ½

**ChatGPTã‚„Claudeã®ã‚ˆã†ã«ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§1æ–‡å­—ãšã¤è¡¨ç¤ºã•ã‚Œã‚‹æ©Ÿèƒ½ã‚’å®Ÿè£…ã—ã¾ã™ã€‚**

ç¾åœ¨ã€Shochan AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ï¼ˆã‚¿ã‚¹ã‚¯ä½œæˆã€å–å¾—ãªã©ï¼‰ã‚’å®Ÿè¡Œã—ãŸå¾Œã€æœ€çµ‚çš„ãªãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã—ã¾ã™ã€‚ã“ã®æœ€çµ‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã€LLMãŒãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ã¨åŒæ™‚ã«ãƒ–ãƒ©ã‚¦ã‚¶ã«è¡¨ç¤ºã™ã‚‹ã“ã¨ã§ã€å¿œç­”æ€§ã®é«˜ã„UXã‚’å®Ÿç¾ã—ã¾ã™ã€‚

### ãªãœå¿…è¦ã‹

| ç¾åœ¨ã®å‹•ä½œ | æœ›ã¾ã—ã„å‹•ä½œ |
|-----------|------------|
| ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå¾…æ©Ÿ â†’ LLMç”Ÿæˆå®Œäº† â†’ ä¸€åº¦ã«å…¨æ–‡è¡¨ç¤º | ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå¾…æ©Ÿ â†’ LLMç”Ÿæˆé–‹å§‹ â†’ **å³åº§ã«**1ãƒˆãƒ¼ã‚¯ãƒ³ãšã¤è¡¨ç¤º |
| **Time to First Token (TTFT)**: é…ã„ | **TTFT**: æ•°ç™¾ãƒŸãƒªç§’ |
| ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“: ã€Œå›ºã¾ã£ã¦ã„ã‚‹?ã€ | ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“: ã€Œå‡¦ç†ä¸­ã ã¨ã‚ã‹ã‚‹ã€ |

---

## å®Ÿç¾ã—ãŸã„ã“ã¨

### ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦–ç‚¹ã§ã®å‹•ä½œ

```
[ãƒ¦ãƒ¼ã‚¶ãƒ¼] ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆã—ã¦
    â†“
[ã‚·ã‚¹ãƒ†ãƒ ] ğŸ”§ Tool call: create_task
[ã‚·ã‚¹ãƒ†ãƒ ] âœ… Tool executed: create_task
    â†“
[ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] ã‚¿... (å³åº§ã«è¡¨ç¤ºé–‹å§‹)
[ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] ã‚¿ã‚¹ã‚¯...
[ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] ã‚¿ã‚¹ã‚¯ã‚’ä½œ...
[ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆã—ã¾...
[ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆã—ã¾ã—ãŸã€‚ (å®Œæˆ)
```

**ãƒã‚¤ãƒ³ãƒˆ**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æœ€çµ‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒ**ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§**å°‘ã—ãšã¤è¡¨ç¤ºã•ã‚Œã‚‹

### æŠ€è¡“çš„ç›®æ¨™

1. **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°**
   - LLMã®ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆã¨åŒæ™‚ã«ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã¸é€ä¿¡
   - Server-Sent Events (SSE) ã‚’ä½¿ç”¨

2. **Time to First Token (TTFT) ã®æœ€å°åŒ–**
   - æœ€åˆã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒæ•°ç™¾ãƒŸãƒªç§’ä»¥å†…ã«è¡¨ç¤ºé–‹å§‹
   - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯å³åº§ã«ã€Œå‡¦ç†ä¸­ã€ã‚’èªè­˜

3. **åŠ¹ç‡çš„ãªAPIä½¿ç”¨**
   - 1å›ã®LLMå‘¼ã³å‡ºã—ã§å®Œçµ
   - ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ã¨ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚’çµ±åˆå‡¦ç†

4. **æ—¢å­˜æ©Ÿèƒ½ã¨ã®çµ±åˆ**
   - ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ï¼ˆcreate_task, get_tasksãªã©ï¼‰ã¯éã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
   - æœ€çµ‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆdone_for_now, request_more_informationï¼‰ã®ã¿ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°

---

## æŠ€è¡“çš„èƒŒæ™¯

### Shochan AI ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web UI    â”‚ (React + Next.js, port 3002)
â”‚ (Frontend)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTP POST /api/agent/query
       â”‚ SSE GET /api/stream/:id
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Express API â”‚ (Node.js + TypeScript, port 3001)
â”‚  (Backend)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â†’ Redis (ä¼šè©±çŠ¶æ…‹ã®æ°¸ç¶šåŒ–)
       â”‚
       â””â”€â†’ OpenAI Responses API (LLMå‘¼ã³å‡ºã—)
```

### ä½¿ç”¨æŠ€è¡“

- **OpenAI Responses API**: Function Calling + ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œ
- **Server-Sent Events (SSE)**: ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¸ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€šä¿¡
- **better-sse**: Expressç”¨ã®SSEãƒ©ã‚¤ãƒ–ãƒ©ãƒª
- **Redis**: ä¼šè©±çŠ¶æ…‹ã®æ°¸ç¶šåŒ–

### OpenAI Responses API ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰

OpenAI Responses APIã¯`stream: true`ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ä»¥ä¸‹ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’é€ä¿¡ã—ã¾ã™ï¼š

| ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ— | èª¬æ˜ | Shochan AI ã§ã®ç”¨é€” |
|--------------|------|-------------------|
| `response.function_call` | Function Call (ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«) æ¤œå‡º | ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œåˆ¤å®š |
| `response.output_text.delta` | ãƒ†ã‚­ã‚¹ãƒˆãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆ1ãƒˆãƒ¼ã‚¯ãƒ³ãšã¤ï¼‰ | UIã¸ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º |
| `response.done` | ã‚¹ãƒˆãƒªãƒ¼ãƒ å®Œäº† | å‡¦ç†çµ‚äº†åˆ¤å®š |
| `error` | ã‚¨ãƒ©ãƒ¼ | ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚° |

---

## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ

### å…¨ä½“ãƒ•ãƒ­ãƒ¼

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ãƒ¦ãƒ¼ã‚¶ãƒ¼  â”‚ ã€Œã‚¿ã‚¹ã‚¯ã‚’ä½œæˆã—ã¦ã€
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
      â”‚ (1) POST /api/agent/query
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Express API    â”‚ conversationId ã‚’å³åº§ã«è¿”å´
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚ (2) ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†é–‹å§‹
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  processAgent   â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚ (3) connected ã‚¤ãƒ™ãƒ³ãƒˆé€ä¿¡ â†’ SSEæ¥ç¶šç¢ºèª
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OpenAI Responses API            â”‚
â”‚ (stream: true)                  â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â”œâ”€â†’ event: response.function_call
      â”‚   â†’ tool_call: create_task (ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ã‚¤ãƒ™ãƒ³ãƒˆé€ä¿¡)
      â”‚
      â”‚   [ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œ: NotionToolExecutor]
      â”‚   â†’ tool_response ã‚¤ãƒ™ãƒ³ãƒˆé€ä¿¡
      â”‚
      â”œâ”€â†’ event: response.function_call
      â”‚   â†’ tool_call: done_for_now
      â”‚
      â””â”€â†’ event: response.output_text.delta (x Nå›)
          â†’ text_chunk ã‚¤ãƒ™ãƒ³ãƒˆé€ä¿¡ (ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ )
          ã€Œã‚¿ã€ã€Œã‚¹ã‚¯ã€ã€Œã‚’ã€ã€Œä½œæˆã€ã€Œã—ã¾ã€ã€Œã—ãŸã€ã€Œã€‚ã€
            â†“ SSE
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚   Web UI    â”‚ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºæ›´æ–°
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ã‚¤ãƒ™ãƒ³ãƒˆãƒ•ãƒ­ãƒ¼è©³ç´°

#### 1. ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‹ã‚‰SSEæ¥ç¶šã¾ã§

```typescript
// 1. ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡
POST /api/agent/query
Body: { message: "ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆã—ã¦" }

// 2. Express API: å³åº§ã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹
Response: { conversationId: "uuid-xxx" }

// 3. ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰: SSEæ¥ç¶šç¢ºç«‹
GET /api/stream/uuid-xxx
Accept: text/event-stream

// 4. Express API: ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ processAgent é–‹å§‹
processAgent(conversationId)
```

#### 2. LLMã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†

```typescript
// OpenAI Responses API ã«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
const stream = await openai.responses.create({
  model: 'gpt-4o',
  instructions: systemPrompt,
  input: inputMessages,
  tools: [create_task, get_tasks, ...],
  stream: true, // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰
});

// ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†
for await (const event of stream) {
  if (event.type === 'response.function_call') {
    // ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«æ¤œå‡º
    // â†’ tool_call ã‚¤ãƒ™ãƒ³ãƒˆã‚’ SSE é€ä¿¡
  }

  if (event.type === 'response.output_text.delta') {
    // ãƒ†ã‚­ã‚¹ãƒˆãƒˆãƒ¼ã‚¯ãƒ³å—ä¿¡
    // â†’ text_chunk ã‚¤ãƒ™ãƒ³ãƒˆã‚’ SSE é€ä¿¡ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰
  }
}
```

#### 3. SSE ã‚¤ãƒ™ãƒ³ãƒˆé€ä¿¡

```typescript
// tool_call ã‚¤ãƒ™ãƒ³ãƒˆ
streamManager.send(conversationId, {
  type: 'tool_call',
  data: { intent: 'create_task', parameters: {...} }
});

// text_chunk ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰
streamManager.send(conversationId, {
  type: 'text_chunk',
  data: { content: 'ã‚¿', messageId: 'msg-123' }
});
streamManager.send(conversationId, {
  type: 'text_chunk',
  data: { content: 'ã‚¹ã‚¯', messageId: 'msg-123' }
});
// ... ç¶šã
```

#### 4. ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰è¡¨ç¤ºæ›´æ–°

```typescript
// SSE ã‚¤ãƒ™ãƒ³ãƒˆå—ä¿¡
handleSSEEvent(event) {
  if (event.type === 'text_chunk') {
    // ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç´¯ç©æ›´æ–°
    setMessages(prev => {
      const lastMessage = prev[prev.length - 1];
      if (lastMessage.id === event.data.messageId) {
        // æ—¢å­˜ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è¿½è¨˜
        return [
          ...prev.slice(0, -1),
          { ...lastMessage, content: lastMessage.content + event.data.content }
        ];
      }
      // æ–°è¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä½œæˆ
      return [...prev, { id: event.data.messageId, content: event.data.content }];
    });
  }
}
```

### ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ãƒãƒƒãƒ”ãƒ³ã‚°

| OpenAI Responses API | Shochan AI Event | ãƒ‡ãƒ¼ã‚¿æ§‹é€  |
|---------------------|------------------|----------|
| `response.function_call` | `tool_call` | `{ type: 'tool_call', data: ToolCall }` |
| `response.output_text.delta` | `text_chunk` | `{ type: 'text_chunk', data: { content: string, messageId: string } }` |
| `error` | `error` | `{ type: 'error', data: { error: string, code: string } }` |

---

## å®Ÿè£…ã‚¹ãƒ†ãƒƒãƒ—

### Phase 0: äº‹å‰æº–å‚™

**ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰çŠ¶æ…‹ã‚’ç¢ºèª**

```bash
git status
# ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¯ãƒªãƒ¼ãƒ³ãªçŠ¶æ…‹ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
```

### Phase 1: Core å‹å®šç¾©ã®è¿½åŠ 

**ãƒ•ã‚¡ã‚¤ãƒ«**: `packages/core/src/types/event.ts`

**ç›®çš„**: `text_chunk` ãŠã‚ˆã³ `connected` ã‚¤ãƒ™ãƒ³ãƒˆå‹ã‚’å®šç¾©

```typescript
/**
 * Text chunk event - streams text tokens in real-time
 * Used for streaming agent responses (done_for_now, request_more_information)
 */
export interface TextChunkEvent extends BaseEvent<'text_chunk'> {
  data: {
    /** ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ï¼ˆ1ãƒˆãƒ¼ã‚¯ãƒ³åˆ†ã¾ãŸã¯è¤‡æ•°ãƒˆãƒ¼ã‚¯ãƒ³ã®ãƒãƒƒãƒ•ã‚¡ï¼‰ */
    content: string;
    /** ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸IDï¼ˆåŒä¸€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒãƒ£ãƒ³ã‚¯ã‚’è­˜åˆ¥ï¼‰ */
    messageId: string;
  };
}

/**
 * Connected event - indicates SSE connection is ready
 * Sent when processAgent starts to confirm SSE connection is established
 */
export interface ConnectedEvent extends BaseEvent<'connected'> {
  data: {
    status: 'ready';
    conversationId: string;
  };
}

// Event union ã«è¿½åŠ 
export type Event =
  | UserInputEvent
  | ToolCallEvent
  | ToolResponseEvent
  | ErrorEvent
  | AwaitingApprovalEvent
  | CompleteEvent
  | TextChunkEvent    // â† è¿½åŠ 
  | ConnectedEvent;   // â† è¿½åŠ 

// Type guards è¿½åŠ 
/**
 * Type guard to check if an event is a text chunk event
 */
export function isTextChunkEvent(event: Event): event is TextChunkEvent {
  return event.type === 'text_chunk';
}

/**
 * Type guard to check if an event is a connected event
 */
export function isConnectedEvent(event: Event): event is ConnectedEvent {
  return event.type === 'connected';
}
```

**ãƒ•ã‚¡ã‚¤ãƒ«**: `packages/core/src/index.ts`

**ç›®çš„**: å‹ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ

```typescript
export type {
  Event,
  UserInputEvent,
  ToolCallEvent,
  ToolResponseEvent,
  ErrorEvent,
  AwaitingApprovalEvent,
  CompleteEvent,
  TextChunkEvent,   // â† è¿½åŠ 
  ConnectedEvent,   // â† è¿½åŠ 
} from './types/event';

export {
  isUserInputEvent,
  isToolCallEvent,
  isToolResponseEvent,
  isErrorEvent,
  isAwaitingApprovalEvent,
  isCompleteEvent,
  isTextChunkEvent,   // â† è¿½åŠ 
  isConnectedEvent,   // â† è¿½åŠ 
} from './types/event';
```

**ãƒ“ãƒ«ãƒ‰**:

```bash
pnpm --filter @shochan_ai/core build
```

### Phase 1.5: Responses API ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ¤œè¨¼

**ç›®çš„**: å®Ÿè£…å‰ã«OpenAI Responses APIã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‹•ä½œã‚’ç¢ºèªã™ã‚‹

**é‡è¦æ€§**:
- APIä»•æ§˜ã®ç†è§£ä¸è¶³ã«ã‚ˆã‚‹ãƒã‚°ã‚’é˜²æ­¢
- ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã¨ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’äº‹å‰ã«æŠŠæ¡
- ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ã¨ãƒ†ã‚­ã‚¹ãƒˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã®ä¸¡æ–¹ã‚’æ¤œè¨¼

**ãƒ•ã‚¡ã‚¤ãƒ«**: `test-responses-streaming.ts`ï¼ˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰

```typescript
import OpenAI from 'openai';

/**
 * Responses APIã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‹•ä½œã‚’æ¤œè¨¼ã™ã‚‹ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
 *
 * æ¤œè¨¼å†…å®¹:
 * 1. ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚° (response.output_text.delta)
 * 2. ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚° (response.function_call)
 *
 * å®Ÿè£…å‰ã«å¿…ãšå®Ÿè¡Œã—ã¦ã€ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã¨æ§‹é€ ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚
 */
async function testResponsesStreaming() {
  const client = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
  });

  console.log('ğŸ” Testing Responses API streaming...\n');

  // Test 1: ãƒ†ã‚­ã‚¹ãƒˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
  console.log('=== Test 1: Text Streaming ===\n');
  try {
    const textStream = await client.responses.create({
      model: 'gpt-4o',
      instructions: 'You are a helpful assistant.',
      input: [{ role: 'user', content: 'Say hello in Japanese' }],
      stream: true,
    });

    console.log('ğŸ“¡ Text streaming events:\n');
    let textEventCount = 0;

    for await (const event of textStream) {
      textEventCount++;
      console.log(`Event #${textEventCount}:`);
      console.log(`  Type: ${event.type}`);
      console.log(`  Data: ${JSON.stringify(event, null, 2)}\n`);
    }

    console.log(`âœ… Text test completed. Total events: ${textEventCount}\n`);
  } catch (error) {
    console.error('âŒ Text test failed:', error);
  }

  // Test 2: ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
  console.log('\n=== Test 2: Tool Call Streaming ===\n');
  try {
    const toolStream = await client.responses.create({
      model: 'gpt-4o',
      instructions: 'You are a helpful task management assistant.',
      input: [{ role: 'user', content: 'Create a task titled "Test Task"' }],
      tools: [
        {
          type: 'function',
          name: 'create_task',
          description: 'Create a new task',
          parameters: {
            type: 'object',
            properties: {
              title: { type: 'string', description: 'Task title' },
            },
            required: ['title'],
          },
        },
      ],
      stream: true,
    });

    console.log('ğŸ“¡ Tool call streaming events:\n');
    let toolEventCount = 0;

    for await (const event of toolStream) {
      toolEventCount++;
      console.log(`Event #${toolEventCount}:`);
      console.log(`  Type: ${event.type}`);
      console.log(`  Data: ${JSON.stringify(event, null, 2)}\n`);
    }

    console.log(`âœ… Tool call test completed. Total events: ${toolEventCount}\n`);
  } catch (error) {
    console.error('âŒ Tool call test failed:', error);
  }
}

testResponsesStreaming();
```

**å®Ÿè¡Œæ–¹æ³•**:

```bash
# ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®š
export OPENAI_API_KEY="your-api-key"

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
npx tsx test-responses-streaming.ts
```

**ç¢ºèªãƒã‚¤ãƒ³ãƒˆ**:
- [x] `response.function_call` ã‚¤ãƒ™ãƒ³ãƒˆã®æ§‹é€ ã¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°
- [x] `response.output_text.delta` ã‚¤ãƒ™ãƒ³ãƒˆã®æ§‹é€ ã¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°
- [x] `response.done` ã‚¤ãƒ™ãƒ³ãƒˆã®å­˜åœ¨ç¢ºèª
- [x] ã‚¤ãƒ™ãƒ³ãƒˆã®é †åºï¼ˆãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ« â†’ ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆï¼‰
- [x] delta ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«å«ã¾ã‚Œã‚‹ãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼ˆ1ãƒˆãƒ¼ã‚¯ãƒ³? è¤‡æ•°ãƒˆãƒ¼ã‚¯ãƒ³?ï¼‰

**æ¤œè¨¼çµæœ**:
```
# æ¤œè¨¼çµæœï¼ˆ2026-01-18å®Ÿæ–½ï¼‰

## Test 1: Text Streaming
- ç·ã‚¤ãƒ™ãƒ³ãƒˆæ•°: 15
- response.output_text.delta ã®å‡ºç¾å›æ•°: 7
- ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹: "ã“ã‚“ã«ã¡ã¯ (Konnichiwa)" (15æ–‡å­—)
- ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: å¯å¤‰ï¼ˆ1-5æ–‡å­—ï¼‰
  - "ã“ã‚“ã«ã¡ã¯", " (", "K", "onn", "ich", "iwa", ")"
- SSEé€ä¿¡é »åº¦: ç´„7ã‚¤ãƒ™ãƒ³ãƒˆ/15æ–‡å­— â†’ **ååˆ†ä½ã„é »åº¦**

## Test 2: Tool Call Streaming
- ç·ã‚¤ãƒ™ãƒ³ãƒˆæ•°: 12
- response.function_call ã®æ¤œå‡º: âœ… æ­£å¸¸
- response.function_call_arguments.delta ã®æ¤œå‡º: âœ… æ­£å¸¸
- JSONãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒãƒãƒ£ãƒ³ã‚¯å˜ä½ã§ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°: âœ… ç¢ºèª

## çµè«–
âœ… OpenAI Responses APIã¯**é©åˆ‡ãªãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º**ã§é€ä¿¡ã—ã¦ã„ã‚‹
âœ… SSEé€ä¿¡é »åº¦ã¯ååˆ†ä½ã„ï¼ˆ7ã‚¤ãƒ™ãƒ³ãƒˆ/15æ–‡å­—ï¼‰
âœ… **Phase 4.5ï¼ˆTextBufferï¼‰ã¯ä¸è¦** - ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ãªã—ã§å®Ÿè£…å¯èƒ½
```

**æ³¨æ„**: ã“ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯å®Ÿè£…å®Œäº†å¾Œã«å‰Šé™¤ã—ã¦ãã ã•ã„ã€‚

### Phase 2: OpenAIClient ã®æ‹¡å¼µ

**ãƒ•ã‚¡ã‚¤ãƒ«**: `packages/client/src/openai.ts`

**ç›®çš„**: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œã®ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ç”Ÿæˆãƒ¡ã‚½ãƒƒãƒ‰è¿½åŠ 

#### 2.1 å‹å®šç¾©ã®è¿½åŠ 

```typescript
// ãƒ•ã‚¡ã‚¤ãƒ«å†’é ­ã«è¿½åŠ 
import { randomUUID } from 'crypto';
import type { ToolCall } from '@shochan_ai/core';

/**
 * Streaming callbacks for real-time token processing
 */
type StreamingCallbacks = {
  /** Callback when tool call is detected */
  onToolCall?: (toolCall: ToolCall) => void;
  /** Callback for each text token (real-time) */
  onTextChunk?: (chunk: string, messageId: string) => void;
};

/**
 * Parameters for generateToolCallWithStreaming
 */
type GenerateToolCallWithStreamingParams = {
  systemPrompt: string;
  inputMessages: Array<unknown>;
  tools?: Array<unknown>;
} & StreamingCallbacks;
```

#### 2.2 ãƒ¡ã‚½ãƒƒãƒ‰å®Ÿè£…

```typescript
/**
 * Generate tool call with streaming support.
 * Streams text tokens in real-time via callbacks.
 *
 * This method uses OpenAI Responses API with stream: true to receive
 * text tokens as they are generated by the LLM.
 *
 * @param systemPrompt - System instructions
 * @param inputMessages - Input messages
 * @param tools - Available tools
 * @param onToolCall - Callback when tool call is detected
 * @param onTextChunk - Callback for each text token (real-time)
 * @returns Tool call result and full text
 */
async generateToolCallWithStreaming({
  systemPrompt,
  inputMessages,
  tools,
  onToolCall,
  onTextChunk,
}: GenerateToolCallWithStreamingParams): Promise<{
  toolCall: ToolCall | null;
  fullText: string;
}> {
  const stream = await this.client.responses.create({
    model: 'gpt-4o',
    instructions: systemPrompt,
    input: inputMessages as OpenAI.Responses.ResponseInput,
    tools: tools?.length ? tools : undefined,
    stream: true, // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰æœ‰åŠ¹åŒ–
  });

  let toolCall: ToolCall | null = null;
  let fullText = '';
  // UUID ã‚’ä½¿ç”¨ã—ã¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸IDã‚’ç”Ÿæˆï¼ˆä¸€æ„æ€§ã‚’ä¿è¨¼ï¼‰
  const messageId = randomUUID();

  for await (const event of stream) {
    switch (event.type) {
      case 'response.function_call':
        // ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«æ¤œå‡º
        toolCall = this.parseToolCall(event);
        onToolCall?.(toolCall);
        break;

      case 'response.output_text.delta':
        // ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯å—ä¿¡ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰
        const chunk = event.delta || '';
        fullText += chunk;
        onTextChunk?.(chunk, messageId);
        break;

      case 'error':
        throw new Error(`OpenAI streaming error: ${JSON.stringify(event)}`);
    }
  }

  return { toolCall, fullText };
}
```

**ãƒ“ãƒ«ãƒ‰**:

```bash
pnpm --filter @shochan_ai/client build
```

### Phase 3: LLMAgentReducer ã®æ›´æ–°

**ãƒ•ã‚¡ã‚¤ãƒ«**: `packages/core/src/agent/llm-agent-reducer.ts`

**ç›®çš„**: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œãƒ¡ã‚½ãƒƒãƒ‰ã®è¿½åŠ 

#### 3.1 å‹åˆ¶ç´„ã®æ›´æ–°

```typescript
export class LLMAgentReducer<
  TLLMClient extends {
    generateToolCall(params: {
      systemPrompt: string;
      inputMessages: Array<unknown>;
      tools?: Array<unknown>;
    }): Promise<{ toolCall: ToolCall | null }>;

    // â† æ–°è¦è¿½åŠ : ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œãƒ¡ã‚½ãƒƒãƒ‰
    generateToolCallWithStreaming(params: {
      systemPrompt: string;
      inputMessages: Array<unknown>;
      tools?: Array<unknown>;
      onToolCall?: (toolCall: ToolCall) => void;
      onTextChunk?: (chunk: string, messageId: string) => void;
    }): Promise<{ toolCall: ToolCall | null; fullText: string }>;
  },
  TTools extends Array<unknown>,
> implements AgentReducer<Thread, Event>
```

#### 3.2 ãƒ¡ã‚½ãƒƒãƒ‰è¿½åŠ 

```typescript
/**
 * Generate next tool call with streaming support.
 * Emits text chunks in real-time for done_for_now/request_more_information.
 *
 * This method is used when streaming the final agent response to the user.
 * Tool calls (create_task, get_tasks, etc.) are non-streaming, but the
 * final message (done_for_now, request_more_information) streams tokens
 * in real-time.
 *
 * @param state - Current thread state
 * @param onToolCall - Callback when tool call is detected
 * @param onTextChunk - Callback for each text token
 * @returns Tool call event or null
 */
async generateNextToolCallWithStreaming(
  state: Thread,
  onToolCall?: (toolCall: ToolCall) => void,
  onTextChunk?: (chunk: string, messageId: string) => void,
): Promise<ToolCallEvent | null> {
  const threadContext = state.serializeForLLM();
  const systemPrompt = this.systemPromptBuilder(threadContext);

  const { toolCall } = await this.llmClient.generateToolCallWithStreaming({
    systemPrompt,
    inputMessages: [{ role: 'user', content: systemPrompt }],
    tools: this.tools,
    onToolCall,
    onTextChunk,
  });

  if (!toolCall) {
    return null;
  }

  return {
    type: 'tool_call',
    timestamp: Date.now(),
    data: toolCall,
  };
}
```

**ãƒ“ãƒ«ãƒ‰**:

```bash
pnpm --filter @shochan_ai/core build
```

### Phase 4: Express API ã®æ›´æ–°

**ãƒ•ã‚¡ã‚¤ãƒ«**: `packages/web/src/routes/agent.ts`

**ç›®çš„**: processAgent é–¢æ•°ã§ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨

#### 4.1 ã‚¤ãƒ³ãƒãƒ¼ãƒˆè¿½åŠ 

```typescript
import {
  Thread,
  LLMAgentReducer,
  NotionToolExecutor,
  isAwaitingApprovalEvent,
  isDoneForNowTool,
  isRequestMoreInformationTool,
  type Event,
  taskAgentTools,
} from '@shochan_ai/core';
```

#### 4.2 processAgent é–¢æ•°ã®æ›´æ–°

```typescript
async function processAgent(
  conversationId: string,
  deps: AgentDependencies,
): Promise<void> {
  const { redisStore, streamManager, reducer, executor } = deps;
  let iterations = 0;

  try {
    let currentThread = await redisStore.get(conversationId);
    if (!currentThread) {
      throw new Error('Conversation not found');
    }

    console.log(`ğŸ¤– Starting agent processing for: ${conversationId}`);

    // SSEæ¥ç¶šç¢ºèª: connected ã‚¤ãƒ™ãƒ³ãƒˆã‚’é€ä¿¡
    streamManager.send(conversationId, {
      type: 'connected',
      timestamp: Date.now(),
      data: { status: 'ready', conversationId },
    });

    // SSEæ¥ç¶šç¢ºç«‹ã‚’å¾…æ©Ÿï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
    // å®Ÿé‹ç”¨ã§ã¯ Redis Pub/Sub ãªã©ã§ã‚ˆã‚Šç¢ºå®Ÿãªæ¥ç¶šç¢ºèªã‚’æ¨å¥¨
    await new Promise(resolve => setTimeout(resolve, 500));

    while (true) {
      if (iterations >= MAX_ITERATIONS) {
        throw new Error(`Maximum iterations (${MAX_ITERATIONS}) reached`);
      }
      iterations++;

      // â˜… ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œãƒ¡ã‚½ãƒƒãƒ‰ã«å¤‰æ›´
      const toolCallEvent = await reducer.generateNextToolCallWithStreaming(
        currentThread,
        // onToolCall: ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«æ¤œå‡ºæ™‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
        (toolCall) => {
          console.log(`ğŸ”§ Tool call detected: ${toolCall.intent}`);
        },
        // onTextChunk: ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯å—ä¿¡æ™‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰
        (chunk, messageId) => {
          const textChunkEvent: Event = {
            type: 'text_chunk',
            timestamp: Date.now(),
            data: {
              content: chunk,
              messageId,
            },
          };
          streamManager.send(conversationId, textChunkEvent);
        },
      );

      if (!toolCallEvent) {
        console.error(`âŒ No tool call generated for ${conversationId}`);
        break;
      }

      // ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ã‚¤ãƒ™ãƒ³ãƒˆé€ä¿¡
      streamManager.send(conversationId, toolCallEvent);
      currentThread = reducer.reduce(currentThread, toolCallEvent);
      await redisStore.set(conversationId, currentThread);

      const toolCall = toolCallEvent.data;

      // done_for_now / request_more_information ã®å ´åˆã¯çµ‚äº†
      if (isDoneForNowTool(toolCall) || isRequestMoreInformationTool(toolCall)) {
        console.log(`âœ… Final response completed: ${toolCall.intent}`);
        break;
      }

      // delete_task ã®æ‰¿èªå¾…ã¡
      if (toolCall.intent === 'delete_task') {
        const awaitingApprovalEvent: Event = {
          type: 'awaiting_approval',
          timestamp: Date.now(),
          data: toolCall,
        };
        streamManager.send(conversationId, awaitingApprovalEvent);
        currentThread = reducer.reduce(currentThread, awaitingApprovalEvent);
        await redisStore.set(conversationId, currentThread);
        break;
      }

      // ãã®ä»–ã®ãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œ
      console.log(`âš™ï¸  Executing tool: ${toolCall.intent}`);
      const result = await executor.execute(toolCall);

      streamManager.send(conversationId, result.event);
      currentThread = reducer.reduce(currentThread, result.event);
      await redisStore.set(conversationId, currentThread);

      console.log(`âœ… Tool executed: ${toolCall.intent}`);
    }
  } catch (error) {
    console.error(`âŒ processAgent error for ${conversationId}:`, error);
    streamManager.send(conversationId, {
      type: 'error',
      timestamp: Date.now(),
      data: {
        error: error instanceof Error ? error.message : String(error),
        code: 'AGENT_PROCESSING_FAILED',
      },
    });
  }
}
```

**ãƒ“ãƒ«ãƒ‰**:

```bash
pnpm --filter @shochan_ai/web build
```

### Phase 4.5: ãƒ†ã‚­ã‚¹ãƒˆãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã®è¿½åŠ ï¼ˆâŒ ã‚¹ã‚­ãƒƒãƒ—ï¼‰

**æ±ºå®š**: **Phase 1.5ã®æ¤œè¨¼ã«ã‚ˆã‚Šã€ã“ã®ãƒ•ã‚§ãƒ¼ã‚ºã¯ä¸è¦ã¨åˆ¤æ–­ã—ã¾ã—ãŸ**

**ç†ç”±**:
- OpenAI Responses APIã¯æ—¢ã«é©åˆ‡ãªãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã§é€ä¿¡ã—ã¦ã„ã‚‹
- SSEé€ä¿¡é »åº¦: ç´„7ã‚¤ãƒ™ãƒ³ãƒˆ/15æ–‡å­— â†’ ååˆ†ä½ã„
- ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹é…å»¶ã®ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã®æ–¹ãŒå¤§ãã„
- å®Ÿè£…ã®è¤‡é›‘ã•ã¨ãƒªã‚½ãƒ¼ã‚¹ç®¡ç†ã‚³ã‚¹ãƒˆãŒä¸è¦

**å…ƒã®ç›®çš„**ï¼ˆå‚è€ƒï¼‰:
- ~~OpenAI APIãŒ1ãƒˆãƒ¼ã‚¯ãƒ³ãšã¤é€ä¿¡ã™ã‚‹å ´åˆã€SSEé€ä¿¡é »åº¦ãŒéå¸¸ã«é«˜ããªã‚‹~~
- ~~50-100msã®ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ã§SSEé€ä¿¡å›æ•°ã‚’å‰Šæ¸›ã—ã€ã‚µãƒ¼ãƒãƒ¼è² è·ã‚’è»½æ¸›~~

**ãƒ•ã‚¡ã‚¤ãƒ«**: `packages/web/src/utils/text-buffer.ts`ï¼ˆæ–°è¦ä½œæˆï¼‰

```typescript
/**
 * Text buffer for streaming optimization.
 *
 * Buffers text chunks and flushes them at regular intervals
 * to reduce SSE overhead. This is useful when OpenAI API sends
 * tokens very frequently (e.g., one token per event).
 *
 * Example:
 * Without buffering: 100 tokens â†’ 100 SSE events
 * With buffering (50ms): 100 tokens â†’ 10-20 SSE events
 *
 * @example
 * const buffer = new TextBuffer(50, (text) => {
 *   streamManager.send(conversationId, {
 *     type: 'text_chunk',
 *     data: { content: text, messageId }
 *   });
 * });
 *
 * buffer.append('Hello');
 * buffer.append(' ');
 * buffer.append('World');
 * // ... after 50ms, sends 'Hello World'
 *
 * buffer.dispose(); // Final flush
 */
export class TextBuffer {
  private buffer = '';
  private timer: NodeJS.Timeout | null = null;
  private readonly flushInterval: number;
  private readonly onFlush: (text: string) => void;
  private disposed = false;

  /**
   * @param flushInterval - Flush interval in milliseconds (recommended: 50-100ms)
   * @param onFlush - Callback when buffer is flushed
   */
  constructor(flushInterval: number, onFlush: (text: string) => void) {
    this.flushInterval = flushInterval;
    this.onFlush = onFlush;
  }

  /**
   * Append text chunk to buffer.
   * Automatically starts timer if not already running.
   */
  append(chunk: string): void {
    if (this.disposed) {
      console.warn('TextBuffer: append() called after dispose()');
      return;
    }

    this.buffer += chunk;

    // Start timer if not already running
    if (!this.timer) {
      this.timer = setTimeout(() => {
        this.flush();
      }, this.flushInterval);
    }
  }

  /**
   * Flush buffer immediately.
   * Sends buffered text via onFlush callback and clears buffer.
   */
  flush(): void {
    if (this.disposed) return;

    if (this.buffer) {
      this.onFlush(this.buffer);
      this.buffer = '';
    }
    if (this.timer) {
      clearTimeout(this.timer);
      this.timer = null;
    }
  }

  /**
   * Clean up resources.
   * Flushes any remaining buffered text and prevents further operations.
   * MUST be called when streaming is complete to avoid memory leaks.
   */
  dispose(): void {
    this.flush();
    this.disposed = true;
  }
}
```

**ä½¿ç”¨ä¾‹**ï¼ˆPhase 4.2 ã® processAgent é–¢æ•°ã‚’æ›´æ–°ï¼‰:

```typescript
import { TextBuffer } from '../utils/text-buffer';

async function processAgent(
  conversationId: string,
  deps: AgentDependencies,
): Promise<void> {
  const { redisStore, streamManager, reducer, executor } = deps;
  let iterations = 0;

  try {
    let currentThread = await redisStore.get(conversationId);
    if (!currentThread) {
      throw new Error('Conversation not found');
    }

    console.log(`ğŸ¤– Starting agent processing for: ${conversationId}`);

    // SSEæ¥ç¶šç¢ºèª
    streamManager.send(conversationId, {
      type: 'connected',
      timestamp: Date.now(),
      data: { status: 'ready', conversationId },
    });
    await new Promise(resolve => setTimeout(resolve, 500));

    while (true) {
      if (iterations >= MAX_ITERATIONS) {
        throw new Error(`Maximum iterations (${MAX_ITERATIONS}) reached`);
      }
      iterations++;

      // ãƒ†ã‚­ã‚¹ãƒˆãƒãƒƒãƒ•ã‚¡ã®åˆæœŸåŒ–
      let textBuffer: TextBuffer | null = null;
      let currentMessageId: string | null = null;

      try {
        const toolCallEvent = await reducer.generateNextToolCallWithStreaming(
          currentThread,
          (toolCall) => {
            console.log(`ğŸ”§ Tool call detected: ${toolCall.intent}`);
          },
          (chunk, messageId) => {
            // æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å ´åˆã€ãƒãƒƒãƒ•ã‚¡ã‚’åˆæœŸåŒ–
            if (!textBuffer || currentMessageId !== messageId) {
              textBuffer?.dispose();
              currentMessageId = messageId;
              textBuffer = new TextBuffer(50, (bufferedText) => {
                const textChunkEvent: Event = {
                  type: 'text_chunk',
                  timestamp: Date.now(),
                  data: {
                    content: bufferedText,
                    messageId,
                  },
                };
                streamManager.send(conversationId, textChunkEvent);
              });
            }
            textBuffer.append(chunk);
          },
        );

        // æœ€çµ‚ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ï¼ˆé‡è¦: ãƒãƒƒãƒ•ã‚¡ã«æ®‹ã£ã¦ã„ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’é€ä¿¡ï¼‰
        textBuffer?.dispose();

        if (!toolCallEvent) {
          console.error(`âŒ No tool call generated for ${conversationId}`);
          break;
        }

        // ... æ®‹ã‚Šã®å‡¦ç†ã¯åŒã˜
      } finally {
        // ã‚¨ãƒ©ãƒ¼æ™‚ã§ã‚‚å¿…ãšãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        textBuffer?.dispose();
      }
    }
  } catch (error) {
    // ... ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
  }
}
```

---

**âœ… Phase 1.5ã®æ¤œè¨¼çµæœã«ã‚ˆã‚Šã€ä¸Šè¨˜ã®å®Ÿè£…ã¯ä¸è¦ã¨ãªã‚Šã¾ã—ãŸã€‚**

Phase 4.2ã®å®Ÿè£…ï¼ˆãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ãªã—ï¼‰ã§ååˆ†ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚

### Phase 5: Web UI ã®æ›´æ–°

#### 5.1 å‹å®šç¾©ã®è¿½åŠ 

**ãƒ•ã‚¡ã‚¤ãƒ«**: `packages/web-ui/types/chat.ts`

```typescript
import type {
  Event,
  ToolCallEvent,
  ToolResponseEvent,
  ErrorEvent,
  CompleteEvent,
  TextChunkEvent,   // â† è¿½åŠ 
  ConnectedEvent,   // â† è¿½åŠ 
} from '@shochan_ai/core'

export type {
  Event,
  ToolCallEvent,
  ToolResponseEvent,
  ErrorEvent,
  CompleteEvent,
  TextChunkEvent,   // â† è¿½åŠ 
  ConnectedEvent,   // â† è¿½åŠ 
}
```

#### 5.2 SSE ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã®è¿½åŠ 

**ãƒ•ã‚¡ã‚¤ãƒ«**: `packages/web-ui/lib/sse-client.ts`

```typescript
const SSE_EVENT_TYPES: ReadonlyArray<Event['type'] | 'connected'> = [
  'user_input',
  'tool_call',
  'tool_response',
  'error',
  'awaiting_approval',
  'complete',
  'text_chunk',   // â† è¿½åŠ 
  'connected',
] as const
```

#### 5.3 text_chunk ã‚¤ãƒ™ãƒ³ãƒˆã®ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

**ãƒ•ã‚¡ã‚¤ãƒ«**: `packages/web-ui/components/chat/chat-interface.tsx`

```typescript
const handleSSEEvent = useCallback((event: Event) => {
  let message: Message | null = null

  switch (event.type) {
    case 'text_chunk':
      // â˜… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ã®å‡¦ç†
      setMessages((prev) => {
        const lastMessage = prev[prev.length - 1]
        const { messageId, content } = event.data

        // æ—¢å­˜ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è¿½è¨˜
        if (lastMessage && lastMessage.id === messageId) {
          return [
            ...prev.slice(0, -1),
            { ...lastMessage, content: lastMessage.content + content },
          ]
        }

        // æ–°è¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä½œæˆ
        return [
          ...prev,
          {
            id: messageId,
            type: 'agent' as const,
            content,
            timestamp: event.timestamp,
          },
        ]
      })
      return

    case 'tool_call':
      // done_for_now/request_more_information ã¯ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§è¡¨ç¤ºã•ã‚Œã‚‹ãŸã‚
      // ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯è¡¨ç¤ºã—ãªã„
      if (event.data.intent === 'done_for_now' ||
          event.data.intent === 'request_more_information') {
        return
      }
      message = createToolCallMessage(event)
      break

    case 'tool_response':
      message = createToolResponseMessage(event)
      break

    case 'complete':
      message = createCompleteMessage(event)
      break

    case 'error':
      message = createErrorMessage(event)
      break
  }

  if (message) {
    setMessages((prev) => [...prev, message])
  }
}, [])
```

**ãƒ“ãƒ«ãƒ‰**:

```bash
pnpm --filter @shochan_ai/web-ui build
```

### Phase 5.5: SSEæ¥ç¶šç¢ºç«‹ç¢ºèªãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã®è¿½åŠ ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

**ç›®çš„**: å›ºå®šå¾…æ©Ÿæ™‚é–“ï¼ˆ500msï¼‰ã§ã¯ãªãã€ç¢ºå®Ÿã«SSEæ¥ç¶šã‚’ç¢ºèªã™ã‚‹

**ç¾çŠ¶ã®èª²é¡Œ**: Phase 4.2ã§ã¯500mså›ºå®šå¾…æ©Ÿã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãŒã€ä»¥ä¸‹ã®å•é¡ŒãŒã‚ã‚‹ï¼š
- ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒé…ã„å ´åˆã€500msã§ã¯ä¸ååˆ†
- ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒé€Ÿã„å ´åˆã€ä¸è¦ãªå¾…æ©Ÿæ™‚é–“

**è§£æ±ºæ–¹æ³•**: `connected` ã‚¤ãƒ™ãƒ³ãƒˆã«ã‚ˆã‚‹æ¥ç¶šç¢ºèª

#### 5.5.1 ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰: æ¥ç¶šç¢ºèªã®å®Ÿè£…

**ãƒ•ã‚¡ã‚¤ãƒ«**: `packages/web-ui/hooks/use-sse.ts`ï¼ˆæ–°è¦ä½œæˆï¼‰

```typescript
import { useState, useEffect, useCallback } from 'react';
import { SSEClient } from '@/lib/sse-client';
import type { Event } from '@/types/chat';

/**
 * Hook for managing SSE connection and receiving events.
 *
 * Features:
 * - Automatic connection establishment
 * - Connection status tracking via 'connected' event
 * - Event buffering
 * - Automatic cleanup on unmount
 *
 * @param conversationId - Conversation ID (null if not started)
 * @param onEvent - Callback for each SSE event
 */
export function useSSE(
  conversationId: string | null,
  onEvent: (event: Event) => void
) {
  const [isConnected, setIsConnected] = useState(false);

  useEffect(() => {
    if (!conversationId) {
      setIsConnected(false);
      return;
    }

    const client = new SSEClient();

    client.connect(
      conversationId,
      (event) => {
        // connected ã‚¤ãƒ™ãƒ³ãƒˆã§æ¥ç¶šç¢ºèª
        if (event.type === 'connected') {
          console.log('âœ… SSE connection established');
          setIsConnected(true);
          return; // connected ã‚¤ãƒ™ãƒ³ãƒˆã¯è¡¨ç¤ºã—ãªã„
        }

        // ãã®ä»–ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’è¦ªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«é€šçŸ¥
        onEvent(event);
      },
      (error) => {
        console.error('âŒ SSE error:', error);
        setIsConnected(false);
      }
    );

    return () => {
      client.disconnect();
      setIsConnected(false);
    };
  }, [conversationId, onEvent]);

  return { isConnected };
}
```

#### 5.5.2 ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®æ›´æ–°

**ãƒ•ã‚¡ã‚¤ãƒ«**: `packages/web-ui/components/chat/chat-interface.tsx`

```typescript
import { useSSE } from '@/hooks/use-sse';

export function ChatInterface() {
  const [messages, setMessages] = useState<Message[]>([])
  const [conversationId, setConversationId] = useState<string | null>(null)

  const handleSSEEvent = useCallback((event: Event) => {
    // ... (æ—¢å­˜ã® handleSSEEvent å®Ÿè£…)
  }, []);

  const { isConnected } = useSSE(conversationId, handleSSEEvent);

  // ... (æ—¢å­˜ã® mutationã€handleSendMessage å®Ÿè£…)

  return (
    <div className="flex flex-col h-full w-full relative">
      <div className="flex justify-between items-center p-4 border-b bg-background">
        <h2 className="text-2xl font-bold">Shochan AI Chat</h2>
        {conversationId && (
          <Badge variant={isConnected ? "default" : "outline"}>
            {isConnected ? 'æ¥ç¶šæ¸ˆã¿' : 'æ¥ç¶šä¸­...'}
          </Badge>
        )}
      </div>

      {/* ... æ®‹ã‚Šã®UI */}
    </div>
  )
}
```

**ãƒ“ãƒ«ãƒ‰**:

```bash
pnpm --filter @shochan_ai/web-ui build
```

**æ³¨æ„**: ã“ã®å®Ÿè£…ã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã™ã€‚ã¾ãšã¯Phase 4.2ã®500mså›ºå®šå¾…æ©Ÿã§ãƒ†ã‚¹ãƒˆã—ã€æ¥ç¶šã‚¿ã‚¤ãƒŸãƒ³ã‚°å•é¡ŒãŒç™ºç”Ÿã™ã‚‹å ´åˆã«Phase 5.5ã‚’é©ç”¨ã—ã¦ãã ã•ã„ã€‚

### Phase 6: çµ±åˆãƒ“ãƒ«ãƒ‰ã¨ãƒ†ã‚¹ãƒˆ

```bash
# å…¨ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰
pnpm -r build

# ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
pnpm --filter @shochan_ai/web dev  # port 3001

# UIèµ·å‹•ï¼ˆåˆ¥ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ï¼‰
pnpm --filter @shochan_ai/web-ui dev  # port 3002
```

---

## ãƒ†ã‚¹ãƒˆè¨ˆç”»

### ãƒ†ã‚¹ãƒˆç’°å¢ƒ

- Redis: `redis://localhost:6379`
- Express API: `http://localhost:3001`
- Web UI: `http://localhost:3002`

### ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹

#### 1. åŸºæœ¬çš„ãªã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‹•ä½œ

**æ‰‹é †**:
1. ãƒ–ãƒ©ã‚¦ã‚¶ã§ `http://localhost:3002` ã‚’é–‹ã
2. ã€Œä»Šæ—¥ã®ã‚¿ã‚¹ã‚¯ã‚’æ•™ãˆã¦ã€ã¨å…¥åŠ›
3. ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡

**æœŸå¾…ã•ã‚Œã‚‹å‹•ä½œ**:
- [ ] `ğŸ”§ Tool call: get_tasks` ãŒå³åº§ã«è¡¨ç¤º
- [ ] ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒ**å°‘ã—ãšã¤**è¡¨ç¤ºã•ã‚Œã‚‹ï¼ˆ1ãƒˆãƒ¼ã‚¯ãƒ³ãšã¤ã¾ãŸã¯ãƒãƒƒãƒ•ã‚¡å˜ä½ï¼‰
- [ ] ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå®Œæˆã™ã‚‹ã¾ã§æ•°ç§’ã‹ã‹ã‚‹
- [ ] æœ€çµ‚çš„ã«å®Œå…¨ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã‚‹

**ç¢ºèªãƒã‚¤ãƒ³ãƒˆ**:
- Time to First Token (TTFT) ãŒ1ç§’ä»¥å†…
- ãƒ†ã‚­ã‚¹ãƒˆãŒæ»‘ã‚‰ã‹ã«è¿½åŠ ã•ã‚Œã‚‹
- ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãªã„

#### 2. ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«é€£é–

**æ‰‹é †**:
1. ã€Œæ˜æ—¥ã®äºˆå®šã§ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆã—ã¦ã€ã¨å…¥åŠ›

**æœŸå¾…ã•ã‚Œã‚‹å‹•ä½œ**:
- [ ] `ğŸ”§ Tool call: create_task`
- [ ] `âœ… Tool executed`
- [ ] ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤ºï¼ˆtool_callã‚¤ãƒ™ãƒ³ãƒˆã¯è¡¨ç¤ºã•ã‚Œãªã„ï¼‰

#### 3. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

**æ‰‹é †**:
1. OpenAI APIã‚­ãƒ¼ã‚’ç„¡åŠ¹åŒ–
2. ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡

**æœŸå¾…ã•ã‚Œã‚‹å‹•ä½œ**:
- [ ] `âŒ Error: ...` ãŒè¡¨ç¤ºã•ã‚Œã‚‹
- [ ] ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã—ãªã„

#### 4. SSEæ¥ç¶šã®ç¢ºèª

**é–‹ç™ºè€…ãƒ„ãƒ¼ãƒ«ç¢ºèª**:
```
Network ã‚¿ãƒ– â†’ stream â†’ Event Stream
```

**æœŸå¾…ã•ã‚Œã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ**:
```
event: connected
data: {"type":"connected","timestamp":1234567890,"data":{"status":"ready","conversationId":"..."}}

event: tool_call
data: {"type":"tool_call", ...}

event: text_chunk
data: {"type":"text_chunk","data":{"content":"ã‚¿","messageId":"..."}}

event: text_chunk
data: {"type":"text_chunk","data":{"content":"ã‚¹ã‚¯","messageId":"..."}}
```

---

## ãƒªã‚¹ã‚¯ã¨å¯¾ç­–

### ãƒªã‚¹ã‚¯1: OpenAI Responses API ã®æŒ™å‹•ãŒä¸æ˜ç­

**å½±éŸ¿**: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¤ãƒ™ãƒ³ãƒˆãŒæœŸå¾…é€šã‚Šé€ä¿¡ã•ã‚Œãªã„

**é‡è¦åº¦**: ğŸ”´ é«˜

**å¯¾ç­–**:
- âœ… **Phase 1.5ã§å®Ÿè£…**: å°è¦æ¨¡ãªãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆã§äº‹å‰æ¤œè¨¼
- OpenAI SDK ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç²¾æŸ»
- ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®è©³ç´°å‡ºåŠ›
- å®Ÿè£…å‰ã«å¿…ãš `test-responses-streaming.ts` ã‚’å®Ÿè¡Œã—ã€çµæœã‚’è¨˜éŒ²

**æ¤œè¨¼é …ç›®**:
- [ ] `response.function_call` ã‚¤ãƒ™ãƒ³ãƒˆã®å­˜åœ¨ç¢ºèª
- [ ] `response.output_text.delta` ã‚¤ãƒ™ãƒ³ãƒˆã®å­˜åœ¨ç¢ºèª
- [ ] ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ç¢ºèª
- [ ] ã‚¹ãƒˆãƒªãƒ¼ãƒ å®Œäº†ã‚¤ãƒ™ãƒ³ãƒˆã®ç¢ºèª

### ãƒªã‚¹ã‚¯2: SSEæ¥ç¶šã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°å•é¡Œ

**å½±éŸ¿**: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é–‹å§‹å‰ã«SSEæ¥ç¶šãŒç¢ºç«‹ã•ã‚Œã¦ã„ãªã„ â†’ åˆæœŸãƒãƒ£ãƒ³ã‚¯ã®æå¤±

**é‡è¦åº¦**: ğŸŸ¡ ä¸­

**å¯¾ç­–**:
- Phase 4.2: 500mså›ºå®šå¾…æ©Ÿï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
- Phase 5.5ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰: `connected` ã‚¤ãƒ™ãƒ³ãƒˆã«ã‚ˆã‚‹æ¥ç¶šç¢ºèª
- ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå‡¦ç†ã®å®Ÿè£…ï¼ˆ2ç§’ï¼‰
- æ¥ç¶šçŠ¶æ…‹ã®UIè¡¨ç¤º

**å®Ÿè£…ã®å„ªå…ˆé †ä½**:
1. ã¾ãšPhase 4.2ã®500mså›ºå®šå¾…æ©Ÿã§ãƒ†ã‚¹ãƒˆ
2. å•é¡ŒãŒç™ºç”Ÿã™ã‚‹å ´åˆã®ã¿Phase 5.5ã‚’é©ç”¨

**å°†æ¥çš„ãªæ”¹å–„æ¡ˆ**:
```typescript
// Redis Pub/Sub ã‚’ä½¿ç”¨ã—ãŸç¢ºå®Ÿãªæ¥ç¶šç¢ºèª
await redisClient.subscribe(`sse:${conversationId}:ready`);
```

### ãƒªã‚¹ã‚¯3: ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯

**å½±éŸ¿**: é•·æ™‚é–“ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒå¢—åŠ 

**é‡è¦åº¦**: ğŸŸ¡ ä¸­

**å¯¾ç­–**:
- ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®é©åˆ‡ãªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
- `for await` ãƒ«ãƒ¼ãƒ—ã®çµ‚äº†ç¢ºèª
- ~~TextBuffer ã® `dispose()` ãƒ¡ã‚½ãƒƒãƒ‰å‘¼ã³å‡ºã—ï¼ˆPhase 4.5ä½¿ç”¨æ™‚ï¼‰~~ â†’ **Phase 4.5ã¯ã‚¹ã‚­ãƒƒãƒ—**
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

**ç›£è¦–æ–¹æ³•**:
```bash
# Node.js ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç›£è¦–
node --expose-gc --max-old-space-size=512 dist/index.js
```

**ç¢ºèªãƒã‚¤ãƒ³ãƒˆ**:
- [x] ~~ã‚¹ãƒˆãƒªãƒ¼ãƒ çµ‚äº†æ™‚ã« `textBuffer?.dispose()` ãŒå‘¼ã°ã‚Œã‚‹ï¼ˆPhase 4.5ä½¿ç”¨æ™‚ï¼‰~~ â†’ **ä¸è¦**
- [ ] ã‚¨ãƒ©ãƒ¼æ™‚ã«ã‚‚ãƒªã‚½ãƒ¼ã‚¹ãŒã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã•ã‚Œã‚‹
- [ ] é•·æ™‚é–“ç¨¼åƒå¾Œã‚‚ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒå®‰å®š

### ãƒªã‚¹ã‚¯4: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä½ä¸‹

**å½±éŸ¿**: é »ç¹ãªSSEé€ä¿¡ã§ã‚µãƒ¼ãƒãƒ¼è² è·å¢—åŠ ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¸¯åŸŸã®æµªè²»

**é‡è¦åº¦**: ğŸŸ¡ ä¸­

**å¯¾ç­–**:
- âœ… **Phase 1.5ã§æ¤œè¨¼æ¸ˆã¿**: OpenAI APIã¯é©åˆ‡ãªãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã§é€ä¿¡
- âŒ **Phase 4.5ï¼ˆTextBufferï¼‰ã¯ã‚¹ã‚­ãƒƒãƒ—**: ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ä¸è¦ã¨åˆ¤æ–­
- SSEé€ä¿¡é »åº¦: ç´„7ã‚¤ãƒ™ãƒ³ãƒˆ/15æ–‡å­— â†’ æ—¢ã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã‚‹

**æ¤œè¨¼çµæœã«åŸºã¥ãåˆ¤æ–­**:
- Phase 1.5ãƒ†ã‚¹ãƒˆã§SSEé€ä¿¡é »åº¦ã¯ååˆ†ä½ã„ã“ã¨ã‚’ç¢ºèª
- 1ç§’ã‚ãŸã‚Š20ã‚¤ãƒ™ãƒ³ãƒˆæœªæº€ã®ãŸã‚ã€ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ä¸è¦
- ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹é…å»¶ã®ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã‚’å›é¿

**ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›®æ¨™**:
- TTFTï¼ˆTime to First Tokenï¼‰: < 500ms âœ…
- SSEé€ä¿¡é »åº¦: ~7 events/15 charsï¼ˆãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ãªã—ï¼‰âœ…
- ã‚µãƒ¼ãƒãƒ¼CPUä½¿ç”¨ç‡: < 50% âœ…

### ãƒªã‚¹ã‚¯5: ã‚¹ãƒˆãƒªãƒ¼ãƒ é€”ä¸­ã®ã‚¨ãƒ©ãƒ¼å‡¦ç†

**å½±éŸ¿**: ã‚¹ãƒˆãƒªãƒ¼ãƒ é€”ä¸­ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã€éƒ¨åˆ†çš„ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒæ®‹ã‚‹

**é‡è¦åº¦**: ğŸŸ¡ ä¸­

**å¯¾ç­–**:
- try-catch ã§ã‚¹ãƒˆãƒªãƒ¼ãƒ å…¨ä½“ã‚’ãƒ©ãƒƒãƒ—
- try-finally ã§ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’ä¿è¨¼ï¼ˆPhase 4.5ä½¿ç”¨æ™‚ï¼‰
- ã‚¨ãƒ©ãƒ¼æ™‚ã« error ã‚¤ãƒ™ãƒ³ãƒˆã‚’é€ä¿¡
- ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã§éƒ¨åˆ†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚¨ãƒ©ãƒ¼è¡¨ç¤ºã«ç½®ãæ›ãˆ

**å®Ÿè£…ä¾‹**:
```typescript
try {
  const toolCallEvent = await reducer.generateNextToolCallWithStreaming(
    currentThread,
    (toolCall) => {
      console.log(`ğŸ”§ Tool call detected: ${toolCall.intent}`);
    },
    (chunk, messageId) => {
      // ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ãªã— - ç›´æ¥SSEé€ä¿¡
      streamManager.send(conversationId, {
        type: 'text_chunk',
        timestamp: Date.now(),
        data: { content: chunk, messageId },
      });
    }
  );
} catch (error) {
  // ã‚¨ãƒ©ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆé€ä¿¡
  streamManager.send(conversationId, {
    type: 'error',
    timestamp: Date.now(),
    data: {
      error: error instanceof Error ? error.message : String(error),
      code: 'STREAMING_ERROR',
    },
  });
}
```

### ãƒªã‚¹ã‚¯6: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ‡æ–­æ™‚ã®å†æ¥ç¶š

**å½±éŸ¿**: SSEæ¥ç¶šãŒåˆ‡æ–­ã•ã‚ŒãŸå ´åˆã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ°—ã¥ã‹ãªã„

**é‡è¦åº¦**: ğŸŸ¢ ä½

**å¯¾ç­–**:
- EventSource ã®è‡ªå‹•å†æ¥ç¶šæ©Ÿèƒ½ã‚’æ´»ç”¨
- æ¥ç¶šçŠ¶æ…‹ã®UIè¡¨ç¤ºï¼ˆPhase 5.5ã§å®Ÿè£…ï¼‰
- å†æ¥ç¶šæ™‚ã®çŠ¶æ…‹å¾©å…ƒ

**EventSource ã®å†æ¥ç¶š**:
```typescript
// EventSource ã¯è‡ªå‹•çš„ã«å†æ¥ç¶šã‚’è©¦ã¿ã‚‹
// retry ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã§å†æ¥ç¶šé–“éš”ã‚’åˆ¶å¾¡å¯èƒ½
streamManager.send(conversationId, {
  retry: 3000, // 3ç§’å¾Œã«å†æ¥ç¶š
});
```

---

## å®Ÿè£…ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### å¿…é ˆé …ç›®

- [ ] **Phase 0**: GitçŠ¶æ…‹ã®ç¢ºèª
- [ ] **Phase 1**: Coreå‹å®šç¾©ã®è¿½åŠ ï¼ˆTextChunkEvent, ConnectedEventï¼‰
- [ ] **Phase 1.5**: Responses APIã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè¡Œ â­
  - [ ] ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
  - [ ] æ¤œè¨¼çµæœã®è¨˜éŒ²
  - [ ] ã‚¤ãƒ™ãƒ³ãƒˆæ§‹é€ ã®ç¢ºèª
- [ ] **Phase 2**: OpenAIClientã®æ‹¡å¼µï¼ˆgenerateToolCallWithStreamingï¼‰
  - [ ] å‹å®šç¾©è¿½åŠ ï¼ˆStreamingCallbacksï¼‰
  - [ ] ãƒ¡ã‚½ãƒƒãƒ‰å®Ÿè£…
  - [ ] ãƒ“ãƒ«ãƒ‰ç¢ºèª
- [ ] **Phase 3**: LLMAgentReducerã®æ›´æ–°
  - [ ] å‹åˆ¶ç´„ã®æ›´æ–°
  - [ ] generateNextToolCallWithStreamingå®Ÿè£…
  - [ ] ãƒ“ãƒ«ãƒ‰ç¢ºèª
- [ ] **Phase 4**: Express APIã®æ›´æ–°ï¼ˆprocessAgentï¼‰
  - [ ] connected ã‚¤ãƒ™ãƒ³ãƒˆé€ä¿¡
  - [ ] ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¡ã‚½ãƒƒãƒ‰ä½¿ç”¨
  - [ ] ãƒ“ãƒ«ãƒ‰ç¢ºèª
- [ ] **Phase 5**: Web UIã®æ›´æ–°
  - [ ] å‹å®šç¾©è¿½åŠ 
  - [ ] SSEã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—è¿½åŠ 
  - [ ] text_chunkãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å®Ÿè£…
  - [ ] ãƒ“ãƒ«ãƒ‰ç¢ºèª
- [ ] **Phase 6**: çµ±åˆãƒ“ãƒ«ãƒ‰ã¨ãƒ†ã‚¹ãƒˆ

### æ¨å¥¨é …ç›®ï¼ˆå¿…è¦ã«å¿œã˜ã¦å®Ÿè£…ï¼‰

- [x] **Phase 4.5**: TextBufferãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã®è¿½åŠ  â†’ **âŒ ã‚¹ã‚­ãƒƒãƒ—æ±ºå®š**
  - Phase 1.5ã®æ¤œè¨¼çµæœã§ãƒˆãƒ¼ã‚¯ãƒ³é€ä¿¡é »åº¦ã¯ååˆ†ä½ã„ã“ã¨ã‚’ç¢ºèª
  - ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ä¸è¦ã¨åˆ¤æ–­
- [ ] **Phase 5.5**: SSEæ¥ç¶šç¢ºç«‹ç¢ºèªãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã®è¿½åŠ 
  - Phase 4ã®500mså›ºå®šå¾…æ©Ÿã§å•é¡ŒãŒç™ºç”Ÿã™ã‚‹å ´åˆã«å®Ÿè£…
  - useSSE hook ä½œæˆ
  - æ¥ç¶šçŠ¶æ…‹ã®UIè¡¨ç¤º

### ãƒ†ã‚¹ãƒˆé …ç›®

- [ ] åŸºæœ¬çš„ãªã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‹•ä½œï¼ˆTTFT < 1ç§’ï¼‰
- [ ] ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«é€£é–
- [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
- [ ] SSEæ¥ç¶šã®ç¢ºèªï¼ˆé–‹ç™ºè€…ãƒ„ãƒ¼ãƒ«ï¼‰
- [ ] é•·æ™‚é–“ç¨¼åƒã§ã®ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãƒã‚§ãƒƒã‚¯ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
- [ ] è¤‡æ•°åŒæ™‚æ¥ç¶šã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

---

## å‚è€ƒè³‡æ–™

- [OpenAI Responses API](https://platform.openai.com/docs/api-reference/responses)
- [Server-Sent Events (MDN)](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events)
- [better-sse](https://github.com/MatthewWid/better-sse)
- [EventSource API (MDN)](https://developer.mozilla.org/en-US/docs/Web/API/EventSource)

---

## ã¾ã¨ã‚

ã“ã®å®Ÿè£…ã«ã‚ˆã‚Šã€ä»¥ä¸‹ã‚’é”æˆã—ã¾ã™ï¼š

âœ… **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°**: LLMã®ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆã¨åŒæ™‚ã«ãƒ–ãƒ©ã‚¦ã‚¶ã¸è¡¨ç¤º
âœ… **TTFTæœ€å°åŒ–**: æ•°ç™¾ãƒŸãƒªç§’ã§æœ€åˆã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¡¨ç¤º
âœ… **åŠ¹ç‡çš„ãªAPIä½¿ç”¨**: 1å›ã®LLMå‘¼ã³å‡ºã—ã§å®Œçµ
âœ… **æ—¢å­˜æ©Ÿèƒ½ã¨ã®çµ±åˆ**: ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ã¯å¾“æ¥é€šã‚Šã€æœ€çµ‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã¿ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
âœ… **ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹æº–æ‹ **: ChatGPT/Claude ã¨åŒç­‰ã®UX
âœ… **æ®µéšçš„ãªæœ€é©åŒ–**: å¿…é ˆå®Ÿè£…â†’ãƒ†ã‚¹ãƒˆâ†’å¿…è¦ã«å¿œã˜ã¦ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°/æ¥ç¶šç¢ºèªã‚’è¿½åŠ 
âœ… **å‹å®‰å…¨æ€§ã®å‘ä¸Š**: UUID ã«ã‚ˆã‚‹ messageId ç”Ÿæˆã€StreamingCallbacks å‹ã€ConnectedEvent å‹

### å®Ÿè£…ã®å„ªå…ˆé †ä½

1. **å¿…é ˆå®Ÿè£…**: Phase 0-6ï¼ˆPhase 4.5, 5.5ã‚’é™¤ãï¼‰
2. **âœ… æ¤œè¨¼å®Œäº†**: Phase 1.5ã®ãƒ†ã‚¹ãƒˆçµæœã«ã‚ˆã‚Šä»¥ä¸‹ã‚’ç¢ºèªï¼š
   - OpenAI APIã¯é©åˆ‡ãªãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã§é€ä¿¡ï¼ˆ7ã‚¤ãƒ™ãƒ³ãƒˆ/15æ–‡å­—ï¼‰
   - **Phase 4.5ï¼ˆTextBufferï¼‰ã¯ä¸è¦** - ã‚¹ã‚­ãƒƒãƒ—æ±ºå®š
3. **æ¡ä»¶ä»˜ãæœ€é©åŒ–**:
   - ~~ãƒˆãƒ¼ã‚¯ãƒ³é€ä¿¡é »åº¦ãŒé«˜ã„ â†’ Phase 4.5 (TextBuffer)~~ â†’ **ä¸è¦ã¨ç¢ºèª**
   - æ¥ç¶šã‚¿ã‚¤ãƒŸãƒ³ã‚°å•é¡Œç™ºç”Ÿ â†’ Phase 5.5 (Connection Confirmation)

å®Ÿè£…å¾Œã€Shochan AIã¯ä¸»è¦AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆChatGPT/Claudeï¼‰ã¨åŒç­‰ã®å¿œç­”æ€§ã¨ä¿¡é ¼æ€§ã‚’æŒã¤ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚
