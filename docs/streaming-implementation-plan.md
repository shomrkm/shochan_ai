# AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè£…è¨ˆç”»

## ç›®æ¬¡

1. [æ¦‚è¦](#æ¦‚è¦)
2. [å®Ÿç¾ã—ãŸã„ã“ã¨](#å®Ÿç¾ã—ãŸã„ã“ã¨)
3. [æŠ€è¡“çš„èƒŒæ™¯](#æŠ€è¡“çš„èƒŒæ™¯)
4. [ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ](#ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ)
5. [å®Ÿè£…ã‚¹ãƒ†ãƒƒãƒ—](#å®Ÿè£…ã‚¹ãƒ†ãƒƒãƒ—)
6. [ãƒ†ã‚¹ãƒˆè¨ˆç”»](#ãƒ†ã‚¹ãƒˆè¨ˆç”»)
7. [ãƒªã‚¹ã‚¯ã¨å¯¾ç­–](#ãƒªã‚¹ã‚¯ã¨å¯¾ç­–)

---

## æ¦‚è¦

### å®Ÿç¾ã—ãŸã„æ©Ÿèƒ½

**ChatGPTã‚„Claudeã®ã‚ˆã†ã«ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§1æ–‡å­—ãšã¤è¡¨ç¤ºã•ã‚Œã‚‹æ©Ÿèƒ½ã‚’å®Ÿè£…ã—ã¾ã™ã€‚**

ç¾åœ¨ã€Shochan AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ï¼ˆã‚¿ã‚¹ã‚¯ä½œæˆã€å–å¾—ãªã©ï¼‰ã‚’å®Ÿè¡Œã—ãŸå¾Œã€æœ€çµ‚çš„ãªãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã—ã¾ã™ã€‚ã“ã®æœ€çµ‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã€LLMãŒãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ã¨åŒæ™‚ã«ãƒ–ãƒ©ã‚¦ã‚¶ã«è¡¨ç¤ºã™ã‚‹ã“ã¨ã§ã€å¿œç­”æ€§ã®é«˜ã„UXã‚’å®Ÿç¾ã—ã¾ã™ã€‚

### ãªãœå¿…è¦ã‹

| ç¾åœ¨ã®å‹•ä½œ | æœ›ã¾ã—ã„å‹•ä½œ |
|-----------|------------|
| ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå¾…æ©Ÿ â†’ LLMç”Ÿæˆå®Œäº† â†’ ä¸€åº¦ã«å…¨æ–‡è¡¨ç¤º | ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå¾…æ©Ÿ â†’ LLMç”Ÿæˆé–‹å§‹ â†’ **å³åº§ã«**1ãƒˆãƒ¼ã‚¯ãƒ³ãšã¤è¡¨ç¤º |
| **Time to First Token (TTFT)**: é…ã„ | **TTFT**: æ•°ç™¾ãƒŸãƒªç§’ |
| ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“: ã€Œå›ºã¾ã£ã¦ã„ã‚‹ï¼Ÿã€ | ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“: ã€Œå‡¦ç†ä¸­ã ã¨ã‚ã‹ã‚‹ã€ |

---

## å®Ÿç¾ã—ãŸã„ã“ã¨

### ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦–ç‚¹ã§ã®å‹•ä½œ

```
[ãƒ¦ãƒ¼ã‚¶ãƒ¼] ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆã—ã¦
    â†“
[ã‚·ã‚¹ãƒ†ãƒ ] ğŸ”§ Tool call: create_task
[ã‚·ã‚¹ãƒ†ãƒ ] âœ… Tool executed: create_task
    â†“
[ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] ã‚¿... (å³åº§ã«è¡¨ç¤ºé–‹å§‹)
[ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] ã‚¿ã‚¹ã‚¯...
[ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] ã‚¿ã‚¹ã‚¯ã‚’ä½œ...
[ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆã—ã¾...
[ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆã—ã¾ã—ãŸã€‚ (å®Œæˆ)
```

**ãƒã‚¤ãƒ³ãƒˆ**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æœ€çµ‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒ**ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§**å°‘ã—ãšã¤è¡¨ç¤ºã•ã‚Œã‚‹

### æŠ€è¡“çš„ç›®æ¨™

1. **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°**
   - LLMã®ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆã¨åŒæ™‚ã«ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã¸é€ä¿¡
   - Server-Sent Events (SSE) ã‚’ä½¿ç”¨

2. **Time to First Token (TTFT) ã®æœ€å°åŒ–**
   - æœ€åˆã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒæ•°ç™¾ãƒŸãƒªç§’ä»¥å†…ã«è¡¨ç¤ºé–‹å§‹
   - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯å³åº§ã«ã€Œå‡¦ç†ä¸­ã€ã‚’èªè­˜

3. **åŠ¹ç‡çš„ãªAPIä½¿ç”¨**
   - 1å›ã®LLMå‘¼ã³å‡ºã—ã§å®Œçµ
   - ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ã¨ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚’çµ±åˆå‡¦ç†

4. **æ—¢å­˜æ©Ÿèƒ½ã¨ã®çµ±åˆ**
   - ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ï¼ˆcreate_task, get_tasksãªã©ï¼‰ã¯éã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
   - æœ€çµ‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆdone_for_now, request_more_informationï¼‰ã®ã¿ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°

---

## æŠ€è¡“çš„èƒŒæ™¯

### Shochan AI ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web UI    â”‚ (React + Next.js, port 3002)
â”‚ (Frontend)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTP POST /api/agent/query
       â”‚ SSE GET /api/stream/:id
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Express API â”‚ (Node.js + TypeScript, port 3001)
â”‚  (Backend)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â†’ Redis (ä¼šè©±çŠ¶æ…‹ã®æ°¸ç¶šåŒ–)
       â”‚
       â””â”€â†’ OpenAI Responses API (LLMå‘¼ã³å‡ºã—)
```

### ä½¿ç”¨æŠ€è¡“

- **OpenAI Responses API**: Function Calling + ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œ
- **Server-Sent Events (SSE)**: ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¸ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€šä¿¡
- **better-sse**: Expressç”¨ã®SSEãƒ©ã‚¤ãƒ–ãƒ©ãƒª
- **Redis**: ä¼šè©±çŠ¶æ…‹ã®æ°¸ç¶šåŒ–

### OpenAI Responses API ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰

OpenAI Responses APIã¯`stream: true`ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ä»¥ä¸‹ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’é€ä¿¡ã—ã¾ã™ï¼š

| ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ— | èª¬æ˜ | Shochan AI ã§ã®ç”¨é€” |
|--------------|------|-------------------|
| `response.function_call` | Function Call (ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«) æ¤œå‡º | ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œåˆ¤å®š |
| `response.output_text.delta` | ãƒ†ã‚­ã‚¹ãƒˆãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆ1ãƒˆãƒ¼ã‚¯ãƒ³ãšã¤ï¼‰ | UIã¸ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º |
| `response.done` | ã‚¹ãƒˆãƒªãƒ¼ãƒ å®Œäº† | å‡¦ç†çµ‚äº†åˆ¤å®š |
| `error` | ã‚¨ãƒ©ãƒ¼ | ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚° |

---

## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ

### å…¨ä½“ãƒ•ãƒ­ãƒ¼

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ãƒ¦ãƒ¼ã‚¶ãƒ¼  â”‚ ã€Œã‚¿ã‚¹ã‚¯ã‚’ä½œæˆã—ã¦ã€
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
      â”‚ (1) POST /api/agent/query
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Express API    â”‚ conversationId ã‚’å³åº§ã«è¿”å´
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚ (2) ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†é–‹å§‹
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  processAgent   â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚ (3) SSEæ¥ç¶šå¾…æ©Ÿ (500ms)
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OpenAI Responses API            â”‚
â”‚ (stream: true)                  â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â”œâ”€â†’ event: response.function_call
      â”‚   â†’ tool_call: create_task (ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ã‚¤ãƒ™ãƒ³ãƒˆé€ä¿¡)
      â”‚
      â”‚   [ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œ: NotionToolExecutor]
      â”‚   â†’ tool_response ã‚¤ãƒ™ãƒ³ãƒˆé€ä¿¡
      â”‚
      â”œâ”€â†’ event: response.function_call
      â”‚   â†’ tool_call: done_for_now
      â”‚
      â””â”€â†’ event: response.output_text.delta (x Nå›)
          â†’ text_chunk ã‚¤ãƒ™ãƒ³ãƒˆé€ä¿¡ (ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ )
          ã€Œã‚¿ã€ã€Œã‚¹ã‚¯ã€ã€Œã‚’ã€ã€Œä½œæˆã€ã€Œã—ã¾ã€ã€Œã—ãŸã€ã€Œã€‚ã€
            â†“ SSE
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚   Web UI    â”‚ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºæ›´æ–°
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ã‚¤ãƒ™ãƒ³ãƒˆãƒ•ãƒ­ãƒ¼è©³ç´°

#### 1. ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‹ã‚‰SSEæ¥ç¶šã¾ã§

```typescript
// 1. ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡
POST /api/agent/query
Body: { message: "ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆã—ã¦" }

// 2. Express API: å³åº§ã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹
Response: { conversationId: "uuid-xxx" }

// 3. ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰: SSEæ¥ç¶šç¢ºç«‹
GET /api/stream/uuid-xxx
Accept: text/event-stream

// 4. Express API: ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ processAgent é–‹å§‹
processAgent(conversationId)
```

#### 2. LLMã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†

```typescript
// OpenAI Responses API ã«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
const stream = await openai.responses.create({
  model: 'gpt-4o',
  instructions: systemPrompt,
  input: inputMessages,
  tools: [create_task, get_tasks, ...],
  stream: true, // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰
});

// ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†
for await (const event of stream) {
  if (event.type === 'response.function_call') {
    // ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«æ¤œå‡º
    // â†’ tool_call ã‚¤ãƒ™ãƒ³ãƒˆã‚’ SSE é€ä¿¡
  }

  if (event.type === 'response.output_text.delta') {
    // ãƒ†ã‚­ã‚¹ãƒˆãƒˆãƒ¼ã‚¯ãƒ³å—ä¿¡
    // â†’ text_chunk ã‚¤ãƒ™ãƒ³ãƒˆã‚’ SSE é€ä¿¡ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰
  }
}
```

#### 3. SSE ã‚¤ãƒ™ãƒ³ãƒˆé€ä¿¡

```typescript
// tool_call ã‚¤ãƒ™ãƒ³ãƒˆ
streamManager.send(conversationId, {
  type: 'tool_call',
  data: { intent: 'create_task', parameters: {...} }
});

// text_chunk ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰
streamManager.send(conversationId, {
  type: 'text_chunk',
  data: { content: 'ã‚¿', messageId: 'msg-123' }
});
streamManager.send(conversationId, {
  type: 'text_chunk',
  data: { content: 'ã‚¹ã‚¯', messageId: 'msg-123' }
});
// ... ç¶šã
```

#### 4. ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰è¡¨ç¤ºæ›´æ–°

```typescript
// SSE ã‚¤ãƒ™ãƒ³ãƒˆå—ä¿¡
handleSSEEvent(event) {
  if (event.type === 'text_chunk') {
    // ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç´¯ç©æ›´æ–°
    setMessages(prev => {
      const lastMessage = prev[prev.length - 1];
      if (lastMessage.id === event.data.messageId) {
        // æ—¢å­˜ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è¿½è¨˜
        return [
          ...prev.slice(0, -1),
          { ...lastMessage, content: lastMessage.content + event.data.content }
        ];
      }
      // æ–°è¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä½œæˆ
      return [...prev, { id: event.data.messageId, content: event.data.content }];
    });
  }
}
```

### ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ãƒãƒƒãƒ”ãƒ³ã‚°

| OpenAI Responses API | Shochan AI Event | ãƒ‡ãƒ¼ã‚¿æ§‹é€  |
|---------------------|------------------|----------|
| `response.function_call` | `tool_call` | `{ type: 'tool_call', data: ToolCall }` |
| `response.output_text.delta` | `text_chunk` | `{ type: 'text_chunk', data: { content: string, messageId: string } }` |
| `error` | `error` | `{ type: 'error', data: { error: string, code: string } }` |

---

## å®Ÿè£…ã‚¹ãƒ†ãƒƒãƒ—

### Phase 0: äº‹å‰æº–å‚™

**ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰çŠ¶æ…‹ã‚’ç¢ºèª**

```bash
git status
# ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¯ãƒªãƒ¼ãƒ³ãªçŠ¶æ…‹ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
```

### Phase 1: Core å‹å®šç¾©ã®è¿½åŠ 

**ãƒ•ã‚¡ã‚¤ãƒ«**: `packages/core/src/types/event.ts`

**ç›®çš„**: `text_chunk` ã‚¤ãƒ™ãƒ³ãƒˆå‹ã‚’å®šç¾©

```typescript
/**
 * Text chunk event - streams text tokens in real-time
 * Used for streaming agent responses (done_for_now, request_more_information)
 */
export interface TextChunkEvent extends BaseEvent<'text_chunk'> {
  data: {
    /** ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ï¼ˆ1ãƒˆãƒ¼ã‚¯ãƒ³åˆ†ï¼‰ */
    content: string;
    /** ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸IDï¼ˆåŒä¸€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒãƒ£ãƒ³ã‚¯ã‚’è­˜åˆ¥ï¼‰ */
    messageId: string;
  };
}

// Event union ã«è¿½åŠ 
export type Event =
  | UserInputEvent
  | ToolCallEvent
  | ToolResponseEvent
  | ErrorEvent
  | AwaitingApprovalEvent
  | CompleteEvent
  | TextChunkEvent; // â† è¿½åŠ 

// Type guard è¿½åŠ 
/**
 * Type guard to check if an event is a text chunk event
 */
export function isTextChunkEvent(event: Event): event is TextChunkEvent {
  return event.type === 'text_chunk';
}
```

**ãƒ•ã‚¡ã‚¤ãƒ«**: `packages/core/src/index.ts`

**ç›®çš„**: å‹ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ

```typescript
export type {
  Event,
  UserInputEvent,
  ToolCallEvent,
  ToolResponseEvent,
  ErrorEvent,
  AwaitingApprovalEvent,
  CompleteEvent,
  TextChunkEvent, // â† è¿½åŠ 
} from './types/event';

export {
  isUserInputEvent,
  isToolCallEvent,
  isToolResponseEvent,
  isErrorEvent,
  isAwaitingApprovalEvent,
  isCompleteEvent,
  isTextChunkEvent, // â† è¿½åŠ 
} from './types/event';
```

**ãƒ“ãƒ«ãƒ‰**:

```bash
pnpm --filter @shochan_ai/core build
```

### Phase 2: OpenAIClient ã®æ‹¡å¼µ

**ãƒ•ã‚¡ã‚¤ãƒ«**: `packages/client/src/openai.ts`

**ç›®çš„**: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œã®ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ç”Ÿæˆãƒ¡ã‚½ãƒƒãƒ‰è¿½åŠ 

```typescript
/**
 * Generate tool call with streaming support.
 * Streams text tokens in real-time via callbacks.
 *
 * @param systemPrompt - System instructions
 * @param inputMessages - Input messages
 * @param tools - Available tools
 * @param onToolCall - Callback when tool call is detected
 * @param onTextChunk - Callback for each text token (real-time)
 * @returns Tool call result and full text
 */
async generateToolCallWithStreaming({
  systemPrompt,
  inputMessages,
  tools,
  onToolCall,
  onTextChunk,
}: {
  systemPrompt: string;
  inputMessages: Array<unknown>;
  tools?: Array<unknown>;
  onToolCall?: (toolCall: ToolCall) => void;
  onTextChunk?: (chunk: string, messageId: string) => void;
}): Promise<{
  toolCall: ToolCall | null;
  fullText: string;
}> {
  const stream = await this.client.responses.create({
    model: 'gpt-4o',
    instructions: systemPrompt,
    input: inputMessages as OpenAI.Responses.ResponseInput,
    tools: tools?.length ? tools : undefined,
    stream: true, // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰
  });

  let toolCall: ToolCall | null = null;
  let fullText = '';
  const messageId = `msg-${Date.now()}`;

  for await (const event of stream) {
    switch (event.type) {
      case 'response.function_call':
        // ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«æ¤œå‡º
        toolCall = this.parseToolCall(event);
        onToolCall?.(toolCall);
        break;

      case 'response.output_text.delta':
        // ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯å—ä¿¡ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰
        const chunk = event.delta || '';
        fullText += chunk;
        onTextChunk?.(chunk, messageId);
        break;

      case 'error':
        throw new Error(`OpenAI streaming error: ${JSON.stringify(event)}`);
    }
  }

  return { toolCall, fullText };
}
```

**ãƒ“ãƒ«ãƒ‰**:

```bash
pnpm --filter @shochan_ai/client build
```

### Phase 3: LLMAgentReducer ã®æ›´æ–°

**ãƒ•ã‚¡ã‚¤ãƒ«**: `packages/core/src/agent/llm-agent-reducer.ts`

**ç›®çš„**: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œãƒ¡ã‚½ãƒƒãƒ‰ã®è¿½åŠ 

#### 3.1 å‹åˆ¶ç´„ã®æ›´æ–°

```typescript
export class LLMAgentReducer<
  TLLMClient extends {
    generateToolCall(params: {
      systemPrompt: string;
      inputMessages: Array<unknown>;
      tools?: Array<unknown>;
    }): Promise<{ toolCall: ToolCall | null }>;

    // â† æ–°è¦è¿½åŠ 
    generateToolCallWithStreaming(params: {
      systemPrompt: string;
      inputMessages: Array<unknown>;
      tools?: Array<unknown>;
      onToolCall?: (toolCall: ToolCall) => void;
      onTextChunk?: (chunk: string, messageId: string) => void;
    }): Promise<{ toolCall: ToolCall | null; fullText: string }>;
  },
  TTools extends Array<unknown>,
> implements AgentReducer<Thread, Event>
```

#### 3.2 ãƒ¡ã‚½ãƒƒãƒ‰è¿½åŠ 

```typescript
/**
 * Generate next tool call with streaming support.
 * Emits text chunks in real-time for done_for_now/request_more_information.
 *
 * @param state - Current thread state
 * @param onToolCall - Callback when tool call is detected
 * @param onTextChunk - Callback for each text token
 * @returns Tool call event or null
 */
async generateNextToolCallWithStreaming(
  state: Thread,
  onToolCall?: (toolCall: ToolCall) => void,
  onTextChunk?: (chunk: string, messageId: string) => void,
): Promise<ToolCallEvent | null> {
  const threadContext = state.serializeForLLM();
  const systemPrompt = this.systemPromptBuilder(threadContext);

  const { toolCall } = await this.llmClient.generateToolCallWithStreaming({
    systemPrompt,
    inputMessages: [{ role: 'user', content: systemPrompt }],
    tools: this.tools,
    onToolCall,
    onTextChunk,
  });

  if (!toolCall) {
    return null;
  }

  return {
    type: 'tool_call',
    timestamp: Date.now(),
    data: toolCall,
  };
}
```

**ãƒ“ãƒ«ãƒ‰**:

```bash
pnpm --filter @shochan_ai/core build
```

### Phase 4: Express API ã®æ›´æ–°

**ãƒ•ã‚¡ã‚¤ãƒ«**: `packages/web/src/routes/agent.ts`

**ç›®çš„**: processAgent é–¢æ•°ã§ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨

#### 4.1 ã‚¤ãƒ³ãƒãƒ¼ãƒˆè¿½åŠ 

```typescript
import {
  Thread,
  LLMAgentReducer,
  NotionToolExecutor,
  isAwaitingApprovalEvent,
  isDoneForNowTool,
  isRequestMoreInformationTool,
  type Event,
  taskAgentTools,
} from '@shochan_ai/core';
```

#### 4.2 processAgent é–¢æ•°ã®æ›´æ–°

```typescript
async function processAgent(
  conversationId: string,
  deps: AgentDependencies,
): Promise<void> {
  const { redisStore, streamManager, reducer, executor } = deps;
  let iterations = 0;

  try {
    let currentThread = await redisStore.get(conversationId);
    if (!currentThread) {
      throw new Error('Conversation not found');
    }

    console.log(`ğŸ¤– Starting agent processing for: ${conversationId}`);

    // SSEæ¥ç¶šç¢ºç«‹ã‚’å¾…æ©Ÿ
    await new Promise(resolve => setTimeout(resolve, 500));

    while (true) {
      if (iterations >= MAX_ITERATIONS) {
        throw new Error(`Maximum iterations (${MAX_ITERATIONS}) reached`);
      }
      iterations++;

      // â˜… ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œãƒ¡ã‚½ãƒƒãƒ‰ã«å¤‰æ›´
      const toolCallEvent = await reducer.generateNextToolCallWithStreaming(
        currentThread,
        // onToolCall: ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«æ¤œå‡ºæ™‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
        (toolCall) => {
          console.log(`ğŸ”§ Tool call detected: ${toolCall.intent}`);
        },
        // onTextChunk: ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯å—ä¿¡æ™‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰
        (chunk, messageId) => {
          const textChunkEvent: Event = {
            type: 'text_chunk',
            timestamp: Date.now(),
            data: {
              content: chunk,
              messageId,
            },
          };
          streamManager.send(conversationId, textChunkEvent);
        },
      );

      if (!toolCallEvent) {
        console.error(`âŒ No tool call generated for ${conversationId}`);
        break;
      }

      // ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ã‚¤ãƒ™ãƒ³ãƒˆé€ä¿¡
      streamManager.send(conversationId, toolCallEvent);
      currentThread = reducer.reduce(currentThread, toolCallEvent);
      await redisStore.set(conversationId, currentThread);

      const toolCall = toolCallEvent.data;

      // done_for_now / request_more_information ã®å ´åˆã¯çµ‚äº†
      if (isDoneForNowTool(toolCall) || isRequestMoreInformationTool(toolCall)) {
        console.log(`âœ… Final response completed: ${toolCall.intent}`);
        break;
      }

      // delete_task ã®æ‰¿èªå¾…ã¡
      if (toolCall.intent === 'delete_task') {
        const awaitingApprovalEvent: Event = {
          type: 'awaiting_approval',
          timestamp: Date.now(),
          data: toolCall,
        };
        streamManager.send(conversationId, awaitingApprovalEvent);
        currentThread = reducer.reduce(currentThread, awaitingApprovalEvent);
        await redisStore.set(conversationId, currentThread);
        break;
      }

      // ãã®ä»–ã®ãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œ
      console.log(`âš™ï¸  Executing tool: ${toolCall.intent}`);
      const result = await executor.execute(toolCall);

      streamManager.send(conversationId, result.event);
      currentThread = reducer.reduce(currentThread, result.event);
      await redisStore.set(conversationId, currentThread);

      console.log(`âœ… Tool executed: ${toolCall.intent}`);
    }
  } catch (error) {
    console.error(`âŒ processAgent error for ${conversationId}:`, error);
    streamManager.send(conversationId, {
      type: 'error',
      timestamp: Date.now(),
      data: {
        error: error instanceof Error ? error.message : String(error),
        code: 'AGENT_PROCESSING_FAILED',
      },
    });
  }
}
```

**ãƒ“ãƒ«ãƒ‰**:

```bash
pnpm --filter @shochan_ai/web build
```

### Phase 5: Web UI ã®æ›´æ–°

#### 5.1 å‹å®šç¾©ã®è¿½åŠ 

**ãƒ•ã‚¡ã‚¤ãƒ«**: `packages/web-ui/types/chat.ts`

```typescript
import type {
  Event,
  ToolCallEvent,
  ToolResponseEvent,
  ErrorEvent,
  CompleteEvent,
  TextChunkEvent, // â† è¿½åŠ 
} from '@shochan_ai/core'

export type {
  Event,
  ToolCallEvent,
  ToolResponseEvent,
  ErrorEvent,
  CompleteEvent,
  TextChunkEvent, // â† è¿½åŠ 
}
```

#### 5.2 SSE ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã®è¿½åŠ 

**ãƒ•ã‚¡ã‚¤ãƒ«**: `packages/web-ui/lib/sse-client.ts`

```typescript
const SSE_EVENT_TYPES: ReadonlyArray<Event['type'] | 'connected'> = [
  'user_input',
  'tool_call',
  'tool_response',
  'error',
  'awaiting_approval',
  'complete',
  'text_chunk', // â† è¿½åŠ 
  'connected',
] as const
```

#### 5.3 text_chunk ã‚¤ãƒ™ãƒ³ãƒˆã®ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

**ãƒ•ã‚¡ã‚¤ãƒ«**: `packages/web-ui/components/chat/chat-interface.tsx`

```typescript
const handleSSEEvent = useCallback((event: Event) => {
  let message: Message | null = null

  switch (event.type) {
    case 'text_chunk':
      // â˜… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ã®å‡¦ç†
      setMessages((prev) => {
        const lastMessage = prev[prev.length - 1]
        const { messageId, content } = event.data

        // æ—¢å­˜ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è¿½è¨˜
        if (lastMessage && lastMessage.id === messageId) {
          return [
            ...prev.slice(0, -1),
            { ...lastMessage, content: lastMessage.content + content },
          ]
        }

        // æ–°è¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä½œæˆ
        return [
          ...prev,
          {
            id: messageId,
            type: 'agent' as const,
            content,
            timestamp: event.timestamp,
          },
        ]
      })
      return

    case 'tool_call':
      // done_for_now/request_more_information ã¯ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§è¡¨ç¤ºã•ã‚Œã‚‹ãŸã‚
      // ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯è¡¨ç¤ºã—ãªã„
      if (event.data.intent === 'done_for_now' ||
          event.data.intent === 'request_more_information') {
        return
      }
      message = createToolCallMessage(event)
      break

    case 'tool_response':
      message = createToolResponseMessage(event)
      break

    case 'complete':
      message = createCompleteMessage(event)
      break

    case 'error':
      message = createErrorMessage(event)
      break
  }

  if (message) {
    setMessages((prev) => [...prev, message])
  }
}, [])
```

**ãƒ“ãƒ«ãƒ‰**:

```bash
pnpm --filter @shochan_ai/web-ui build
```

### Phase 6: çµ±åˆãƒ“ãƒ«ãƒ‰ã¨ãƒ†ã‚¹ãƒˆ

```bash
# å…¨ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰
pnpm -r build

# ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
pnpm --filter @shochan_ai/web dev  # port 3001

# UIèµ·å‹•ï¼ˆåˆ¥ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ï¼‰
pnpm --filter @shochan_ai/web-ui dev  # port 3002
```

---

## ãƒ†ã‚¹ãƒˆè¨ˆç”»

### ãƒ†ã‚¹ãƒˆç’°å¢ƒ

- Redis: `redis://localhost:6379`
- Express API: `http://localhost:3001`
- Web UI: `http://localhost:3002`

### ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹

#### 1. åŸºæœ¬çš„ãªã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‹•ä½œ

**æ‰‹é †**:
1. ãƒ–ãƒ©ã‚¦ã‚¶ã§ `http://localhost:3002` ã‚’é–‹ã
2. ã€Œä»Šæ—¥ã®ã‚¿ã‚¹ã‚¯ã‚’æ•™ãˆã¦ã€ã¨å…¥åŠ›
3. ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡

**æœŸå¾…ã•ã‚Œã‚‹å‹•ä½œ**:
- [ ] `ğŸ”§ Tool call: get_tasks` ãŒå³åº§ã«è¡¨ç¤º
- [ ] ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒ**1ãƒˆãƒ¼ã‚¯ãƒ³ãšã¤**è¡¨ç¤ºã•ã‚Œã‚‹
- [ ] ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå®Œæˆã™ã‚‹ã¾ã§æ•°ç§’ã‹ã‹ã‚‹
- [ ] æœ€çµ‚çš„ã«å®Œå…¨ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã‚‹

**ç¢ºèªãƒã‚¤ãƒ³ãƒˆ**:
- Time to First Token (TTFT) ãŒ1ç§’ä»¥å†…
- ãƒ†ã‚­ã‚¹ãƒˆãŒæ»‘ã‚‰ã‹ã«è¿½åŠ ã•ã‚Œã‚‹
- ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãªã„

#### 2. ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«é€£é–

**æ‰‹é †**:
1. ã€Œæ˜æ—¥ã®äºˆå®šã§ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆã—ã¦ã€ã¨å…¥åŠ›

**æœŸå¾…ã•ã‚Œã‚‹å‹•ä½œ**:
- [ ] `ğŸ”§ Tool call: create_task`
- [ ] `âœ… Tool executed`
- [ ] `ğŸ”§ Tool call: done_for_now`
- [ ] ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤º

#### 3. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

**æ‰‹é †**:
1. OpenAI APIã‚­ãƒ¼ã‚’ç„¡åŠ¹åŒ–
2. ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡

**æœŸå¾…ã•ã‚Œã‚‹å‹•ä½œ**:
- [ ] `âŒ Error: ...` ãŒè¡¨ç¤ºã•ã‚Œã‚‹
- [ ] ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã—ãªã„

#### 4. SSEæ¥ç¶šã®ç¢ºèª

**é–‹ç™ºè€…ãƒ„ãƒ¼ãƒ«ç¢ºèª**:
```
Network ã‚¿ãƒ– â†’ stream â†’ Event Stream
```

**æœŸå¾…ã•ã‚Œã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ**:
```
event: tool_call
data: {"type":"tool_call", ...}

event: text_chunk
data: {"type":"text_chunk","data":{"content":"ã‚¿",...}}

event: text_chunk
data: {"type":"text_chunk","data":{"content":"ã‚¹ã‚¯",...}}
```

---

## ãƒªã‚¹ã‚¯ã¨å¯¾ç­–

### ãƒªã‚¹ã‚¯1: OpenAI Responses API ã®æŒ™å‹•ãŒä¸æ˜ç­

**å½±éŸ¿**: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¤ãƒ™ãƒ³ãƒˆãŒæœŸå¾…é€šã‚Šé€ä¿¡ã•ã‚Œãªã„

**å¯¾ç­–**:
- å°è¦æ¨¡ãªãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆã§äº‹å‰æ¤œè¨¼
- OpenAI SDK ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç²¾æŸ»
- ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®è©³ç´°å‡ºåŠ›

### ãƒªã‚¹ã‚¯2: SSEæ¥ç¶šã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°å•é¡Œ

**å½±éŸ¿**: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é–‹å§‹å‰ã«SSEæ¥ç¶šãŒç¢ºç«‹ã•ã‚Œã¦ã„ãªã„

**å¯¾ç­–**:
- `processAgent` å†…ã§500msã®å¾…æ©Ÿæ™‚é–“ã‚’ç¶­æŒ
- SSEæ¥ç¶šç¢ºç«‹ã®ãƒ­ã‚°ç¢ºèª
- å¿…è¦ã«å¿œã˜ã¦å¾…æ©Ÿæ™‚é–“ã‚’èª¿æ•´

### ãƒªã‚¹ã‚¯3: ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯

**å½±éŸ¿**: é•·æ™‚é–“ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒå¢—åŠ 

**å¯¾ç­–**:
- ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®é©åˆ‡ãªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
- `for await` ãƒ«ãƒ¼ãƒ—ã®çµ‚äº†ç¢ºèª
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

### ãƒªã‚¹ã‚¯4: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä½ä¸‹

**å½±éŸ¿**: é »ç¹ãªSSEé€ä¿¡ã§ã‚µãƒ¼ãƒãƒ¼è² è·å¢—åŠ 

**å¯¾ç­–**:
- ãƒãƒ£ãƒ³ã‚¯ã®ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°æ¤œè¨ï¼ˆè¤‡æ•°ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ã¾ã¨ã‚ã¦é€ä¿¡ï¼‰
- SSEé€ä¿¡é »åº¦ã®èª¿æ•´
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã®å®Ÿæ–½

---

## å‚è€ƒè³‡æ–™

- [OpenAI Responses API](https://platform.openai.com/docs/api-reference/responses)
- [Server-Sent Events (MDN)](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events)
- [better-sse](https://github.com/MatthewWid/better-sse)
- [EventSource API (MDN)](https://developer.mozilla.org/en-US/docs/Web/API/EventSource)

---

## ã¾ã¨ã‚

ã“ã®å®Ÿè£…ã«ã‚ˆã‚Šã€ä»¥ä¸‹ã‚’é”æˆã—ã¾ã™ï¼š

âœ… **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°**: LLMã®ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆã¨åŒæ™‚ã«ãƒ–ãƒ©ã‚¦ã‚¶ã¸è¡¨ç¤º
âœ… **TTFTæœ€å°åŒ–**: æ•°ç™¾ãƒŸãƒªç§’ã§æœ€åˆã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¡¨ç¤º
âœ… **åŠ¹ç‡çš„ãªAPIä½¿ç”¨**: 1å›ã®LLMå‘¼ã³å‡ºã—ã§å®Œçµ
âœ… **æ—¢å­˜æ©Ÿèƒ½ã¨ã®çµ±åˆ**: ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ã¯å¾“æ¥é€šã‚Šã€æœ€çµ‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã¿ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
âœ… **ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹æº–æ‹ **: ChatGPT/Claude ã¨åŒç­‰ã®UX

å®Ÿè£…å¾Œã€Shochan AIã¯ä¸»è¦AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨åŒç­‰ã®å¿œç­”æ€§ã‚’æŒã¤ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚
